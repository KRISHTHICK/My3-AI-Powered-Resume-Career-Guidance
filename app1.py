import streamlit as st
from langchain_community.llms import Ollama
from langchain.chains import RetrievalQA
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from langchain.text_splitter import CharacterTextSplitter
import fitz  # PyMuPDF
import matplotlib.pyplot as plt
import seaborn as sns

# ------------------- Extract Text -------------------
def extract_text_from_pdf(file):
    doc = fitz.open(stream=file.read(), filetype="pdf")
    text = "\n".join(page.get_text() for page in doc)
    return text

# ------------------- Vector Store -------------------
@st.cache_resource
def create_vectorstore(text):
    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    docs = splitter.create_documents([text])
    embed_model = OllamaEmbeddings(model="nomic-embed-text")
    return Chroma.from_documents(docs, embed_model)

# ------------------- QA Chain -------------------
def make_qa_chain(text):
    vectorstore = create_vectorstore(text)
    retriever = vectorstore.as_retriever()
    llm = Ollama(model="llama3")
    return RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# ------------------- Streamlit App -------------------
st.set_page_config(page_title="A2A Career Coach", layout="wide")
st.title("üëî A2A Career Coach")
st.caption("Upload your resume and get AI-powered insights.")

uploaded_file = st.file_uploader("üìÑ Upload your Resume (PDF)", type="pdf")

if uploaded_file:
    text = extract_text_from_pdf(uploaded_file)
    st.success("‚úÖ Resume Uploaded Successfully")
    qa_chain = make_qa_chain(text)

    question = st.chat_input("Ask a career question based on your resume...")

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    if question:
        answer = qa_chain.run(question)
        st.session_state.chat_history.append((question, answer))

    for q, a in st.session_state.chat_history:
        with st.chat_message("user"):
            st.markdown(q)
        with st.chat_message("assistant"):
            st.markdown(a)

    # üìà Skill Frequency Visualization
    st.divider()
    st.subheader("üìä Skill Frequency Insight")
    with st.expander("Show Skill Insights"):
        words = [w for w in text.split() if len(w) > 4]
        freq = {}
        for word in words:
            freq[word] = freq.get(word, 0) + 1
        top = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:10]
        labels, values = zip(*top)
        fig, ax = plt.subplots()
        sns.barplot(x=list(values), y=list(labels), ax=ax)
        st.pyplot(fig)

    # ‚úçÔ∏è Blog Generation
    st.divider()
    if st.button("‚úçÔ∏è Generate Career Advice Blog"):
        blog_prompt = "Write a career guidance blog based on this resume. Suggest job roles, skill improvements, and industries to target."
        blog = qa_chain.run(blog_prompt)
        st.text_area("AI-Generated Blog:", blog, height=300)

else:
    st.info("‚¨ÖÔ∏è Upload a resume PDF to get started.")

